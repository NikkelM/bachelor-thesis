\begin{jointwork}
	In this section we will take a look at the different approaches we took to monitoring agents in our framework, explaining the reasons why we chose to implement specific features and how they help us in determining an agents strengths and weaknesses.
\end{jointwork}

\section{When to monitor what}

Our workflow (which will be explained in more detail in \nameref{chapter:OurWorkflow}) can generally be split into two parts when it comes to monitoring and evaluation of agents. In the future, when talking about the \emph{workflow} we will be talking about the process of configuring and starting a training session, where a Reinforcement-Learning agent is being trained on a specific marketplace against competitors. The \emph{workflow} also includes the subsequent collection of data used to evaluate the agent's performance. We are also introducing the term of the \emph{complete agent} in this section, which will be used to refer to both Reinforcement-Learning agents that have been fully trained as well as rule-based agents which do not need training. 

\begin{enumerate}
	\item During training: Having data available as soon as possible without having to wait for a long training session to end is crucial to an efficient workflow. Our framework enables us to analyze and visualize data while a training session is still running \todo{Implement this feature. It should at least be able to temporarily halt the training to start an intermediate training session}. This enables us to filter out agents with sub-par performance prematurely. This can be done using user-defined threshholds or on the basis of previoulsly collected data (e.g. only keeping agents that are performing better than at least 50\% of other agents after the same amount of training in comparable scenarios.) \todo{Also implement this feature. Allow users to set rules for when a training session should be terminated if the agent is not performing well at a certain point. Also, it should be able to give the program a set of datapoints and have it set rules if possible}

	\item On complete agents: After a training session has finished we have a complete and final set of data available for an agent, which enables us to perform more thorough and reliable tests. These can include simulating runs of a marketplace to gather data on the agent's performance in different scenarios and against different competitors, or running a static analysis of the agent's policy in different market states. The tools available for trained agents are in the same way also usable on rule-based agents.
\end{enumerate}

In the following sections, we will take a look at all of the tools our framework provides for monitoring agents. We will also discuss features that are currently not available, explaining how they could benefit the entire workflow or enrich the overall experience.

\section{Monitoring during a training session}

\subsection{Tensorboard? (Not built by us)}
\subsection{Live-monitoring}

\section{Monitoring complete agents}

\subsection{Agent-monitoring}
\subsection{Exampleprinter}
\subsection{Policyanalyzer}