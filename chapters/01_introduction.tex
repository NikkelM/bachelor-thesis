\begin{jointwork}
	This thesis builds upon the bachelors project `Online Marketplace Simulation: A Testbed for Self-Learning Agents' of the Enterprise Platform and Integration Concepts research group at the Hasso-Plattner-Institute. Therefore, the project will be referenced and all examples and experiments will have been conducted using its framework.
\end{jointwork}

\section{Objective of the Thesis}

This thesis introduces ways to monitor and evaluate different agents (rule-based as well as trained using various Reinforcement-Learning approaches) tasked with dynamically pricing products in a \emph{Circular Economy} marketplace.
% Since the terms \emph{Reliability} and \emph{Robustness} can be interpreted differently depending on context and personal experience, we will define our usage in the \nameref{subsec:ReliabilityAndRobustness} section. Following the term definitions, we will give a short introduction and explanation of what a Circular Economy market is (\nameref{sec:CircularEconomy}) as well as what Reinforcement Learning is and how we employ the technique in our framework (\nameref{subsec:ReinforcementLearningIntroduction}).
We will first introduce the general concept of a \emph{recommerce} market (\nameref{sec:CircularEconomy}) and the structure of the framework we built (\todo{nameref in intro, where the diagram will be}). In \nameref{ch:RelatedWork} we will explore other aproaches to market simulations for dynamic pricing, the general concept of Reinforcement-Learning as well as novel approaches to evaluating those agents. \todo{novel implies plural, currently only one new approach}This will be followed by an overview of the specific features of a \emph{recommerce} market that we implemented in \nameref{ch:SimulatingMarketplace}. In \nameref{ch:Approaches} we will give a detailed explanation of the different tools we built and used to monitor and evaluate our different agents. These tools will be put into context in \nameref{ch:OurWorkflow}, where the different parts of the framework will be joined together and its modularity is highlighted\todo{Highlgiht modularity in that chapter ;)}. Finally, we will conduct a number of experiments using out tools in \nameref{ch:InterpretResults} and highlight both strengths and shortcomings of our implementation. \todo{Do I mention `shortcomings'?}

% \subsection*{Reliability and Robustness}\label{subsec:ReliabilityAndRobustness}
% \todo{Alex: `Hast du für Reliability und Robustness irgendeine Quantifizierung? Wenn ja, und wenn die Erklärung kompakt ist würde ich die hier schon bringen.' Quantifizierung der Begriffe: Welche Metriken kommen zum Einsatz, um die jeweils zu beurteilen? Warum?}
% \begin{enumerate}
% 	\item \emph{Reliability}: With \emph{Reliability}, we describe the ability of an agent to be able to transfer knowledge of a certain type of marketplace and/or against a certain opponent over to a different scenario. If Agent A performs well against Agent B on marketplace M, does it perform the same against Agent C on marketplace M, or against Agent B on marketplace N?
% 	\item \emph{Robustness}: \emph{Robustness} is the property that describes how well an agent performs over a longer period of time. In a real-world marketplace, consistency is key to success, so finding profitability outliers and their causes are a central part of evaluating an agent's Robustness.
% \end{enumerate}

\section{The Circular Economy model}\label{sec:CircularEconomy}\todo{Alex: `Die Erklärung des Marktes ist noch sehr knapp gehalten und beschränkt sich augenscheinlich mehr auf die daraus resultierenden Preise als den Flow der Produkte. Letzteres wäre aber ein wichtiger Aspekt (Erklärung? Vlt. würde auch Visualisierung helfen)' Am Ende vom ersten Absatz: `This allows the simulated customers to return/re-sell products...'}
The main goal of the aforementioned bachelors project was to develop a realistic online marketplace that simulates a Circular Economy. A market is most commonly referred to as being a \emph{Circular Economy} if it includes the three activities of reduce, reuse and recycle \cite{circularEconomyDefinition}. This means that while in a classical Linear Economy market each product is being sold once at its \emph{new price} and after use being thrown away, in a Circular Economy, recycling and thereby waste reduction is a major focus. In our project, we modelled this by adding two additional price channels, \emph{re-buy price} and \emph{used price}, to the pre-existing \emph{new price} of a product.

The \emph{re-buy price} is defined as the price a vendor is willing to pay a customer to buy back a used product, while the \emph{used price} is defined as the price the vendor sets for products they previously bought back and now want to sell alongside new products (whose price is defined by the \emph{new price}). We will go into more detail of how we modelled different market scenarios in \nameref{sec:MarketScenarios}.

In the context of e-commerce, Circular Economy markets are also referred to as \emph{recommerce} markets.

From now on, when mentioning a general \emph{market} or \emph{marketplace}, we are referencing the Circular Economy marketplace with re-buy prices.

\subsection*{Using the simulated marketplace to train agents}\label{subsec:ReinforcementLearningIntroduction}\todo{Alex: `Du bringst in der Einführung in der Erklärung des Marktes recht überraschend die Grundidee von RL. Das würde ich vielleicht in eine Extra-Sektion schieben.' -> evtl. in related work?}

After the initial market was modelled the goal was to train agents using different reinforcement-learning algorithms to dynamically set prices on this marketplace, both in monopolistic scenarios as well as in competition with rule-based vendors which set prices following a strict set of pre-defined rules. These rules can range from simply undercutting the lowest competitor's price to more advanced techniques such as smart inventory management and reliance on previous sales data, which can in some cases and combinations even lead to price-fixing and -gouging between competing vendors (see \nameref{bullet:GameTheory} for a more in-depth analysis). Furthermore, functionality was added that allows for different Reinforcement learning algorithms to be trained against each other on the same marketplace, as well as functionality for so-called \emph{self-play}, where an agent plays against itself, or more precisely, against its own policy.

% [hbt!] tells Latex to not put the figure at the top/bottom/newpage but exactly where defined
\begin{figure}
	\centering
	\includegraphics[height = 7 cm]{images/RL-Overview.png}\\[1 ex]
	\caption{The standard reinforcement-learning model in the context of our market.}\label{fig:IntroRLDiagram}
\end{figure}

Reinforcement-learning agents are trained through a process of trial-and-error. They interact with the market through an observable state and an action which influences the following state. \Cref{fig:IntroRLDiagram} illustrates the RL-model in the context of our market.\todo{re-buy instead of buy-back in the diagram}\todo{Create a \emph{nicer} diagram with the three prices} The goal of the agent is to maximize its reinforcement signal, which in our case is the profit the agent made during the last episode, since we want to train agents to maximize profits on real markets. An episode consists of a fixed, configurable number of timesteps, where in each step each vendor (agent) sets their prices and customers make purchasing decisions. By observing which prices lead to which profits (reinforcement signal), the agents get more effective in their pricing decisions over the course of training.