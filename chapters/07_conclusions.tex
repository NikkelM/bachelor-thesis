\label{ch:Conclusions}

\begin{jointwork}
	In this final chapter, we will look back at our framework and monitoring tools and give an outlook on how different parts of the framework, and the monitoring tools especially, could be improved in the future.
\end{jointwork}

\section{Modelling a realistic \emph{recommerce} marketplace}\label{sec:DivergingFromRealMarket}\todo{Add something about market circumstances, customers, and close with modularity argument. Section needs more structure}

We do not claim in any way that our simulation framework is exhaustive or complete. This chapter will focus on ways in which different parts of it could or should be improved in the future, to model a more realistic marketplace.

\todo{Number of pages: This next paragraph could be removed for space reasons}There are a number of parameters influencing market dynamics, small and great, which have not been modelled due to time constraints or their unpredictability in their effect on the market state or customer decisions. Seasonality of demand, customer retention, loyalty through branding and unforeseen effects on market dynamics such as global events (for example, the Covid-19 pandemic) are just some of the places where our market simulation diverges from the real market, following its inability to model these circumstances. However, all of these factors are either very rare in nature (global, unforeseen events), only applicable to a subset of markets (brand loyalty) or can initially be discarded as their effect on market dynamics is predictable, making them a lower priority than other parameters (seasonality).

The factors mentioned above all have an impact on both Linear and Circular markets, but there are also a number of parameters that are specific to Circular or even recommerce markets in particular. In the modern recommerce market, more and more consumers make their initial purchasing decisions with the product's eventual resale value already in mind~\cite{ShoppingResaleValue}. Additionally, a great number of different motivations for choosing second-hand or refurbished products over traditional new ones can be identified. An exemplary study conducted in 2008 (\cite{SecondHandMotives}) classified such motivations into 15 different categories (see \Cref{tab:SecondHandMotives}), all of which could be used to add dimensions to customer behaviour in our simulation framework, thereby making the whole simulation more realistic.

Of course, this results in the fact that our framework can not be used out-of-the-box for any kind of market. However, great care was taken during the development process to build each part of the simulation in a modular way, so that new functionality can easily be integrated into it. Marketplaces, customers and vendors (Rule-Based as well as those using RL) have all been implemented as classes disconnected from each other, so that new variants of each can easily be added to the pool of available options to be used in experiments. The same goes for our monitoring tools, all of which have been built to work with any (valid) combination of input parameters. For reference, all of the classes shown in \Cref{fig:OverviewDiagram} can be extended or replaced with ease. Please also refer to \cite{LeoThesis} for more information on the modularity of our framework.

The lack of realism on certain areas of the framework does not directly impact the way that our monitoring tools work or can be used. It must however be noted that the interpretation of results must always be based on the knowledge of these limitations.

\section{Improving our monitoring tools}

While the previous section focussed on way in which our simulation framework could be extended to be more realistic, this section will instead focus on ways in which our various monitoring tools could be improved. While all of the tools we currently have available are able to do what is expected of them, and they each have their own strengths, there are still a number of ways that the different tools could be enhanced.

%% This has now been added and is also shown in the AllMetrics diagram already.
% Before going into detail about the different tools, there is one enhancement which concerns all of our tools. As some tools are older than others and not only the tools itself but also the way we simulate our market has changed over time during development, not all tools record the same data. For example, the Exampleprinter records all prices set by vendors, but does not show a breakdown of profits between the different retail channels. On the other hand, the Agent-monitoring does offer such a breakdown, but does not record the vendors' actions and thereby prices. This can lead to confusion, as users may expect a certain type of diagram to be created when using one tool or the other. So an important, though perhaps time-intensive, enhancement would be to \textbf{unify the data that is being recorded across all monitoring tools}.

\subsection{Live-monitoring}\label{subsec:FutureLiveMonitoring}

Currently, the Live-monitoring tool works by first taking and visualizing all the data collected during a training run, and then running the Agent-monitoring tool on the saved intermediate models. The biggest downside to this is that users need to wait until the training session has finished before the Agent-monitoring is run, meaning that a lot of potential information is lost. Imagine a scenario where a training session was initialized to run for 10,000 episodes, saving intermediate models each 1,000 episodes. In the end, when the Live-monitoring tool is run, the user may find that the best model was the one saved after 3,000 episodes, meaning that a lot of time was wasted training an additional 7,000 episodes. The possibility of this happening may at first seem counterintuitive, but is a common phenomenon when training RL agents, known as \emph{Catastrophic Forgetting} (see also \cite{CatastrophicForgetting}). By improving the Live-monitoring tool with an option to \textbf{run the Agent-monitoring whenever an intermediate model is saved}, the user would be able to recognize such trends much faster and terminate the experiment at the right time. This feature could be further enhanced with a smart built-in option that \textbf{terminates the experiment for the user if a downward trend in performance is detected}. Specific thresholds for these terminations should also optionally be \textbf{set by the user}. For this, the data created during the Agent-monitoring tool would need to be saved in a machine-readable form - graphs and diagrams are not useful here.

\subsection{Agent-monitoring}\label{subsec:FutureAgentMonitoring}

This brings us to improvements that could be made to the Agent-monitoring tool. At the moment, a lot of data is recorded when simulating the marketplace, but only graphs and diagrams are created as a result of the simulation. By \textbf{giving users the option to have data saved as (for example) \texttt{.csv} files}, users would be enabled to use the results of the simulation in other ways more easily, even for monitoring and evaluation tools completely disconnected from our own framework and the tools we provide. Reproducibility is also a major concern when it comes to evaluating simulation results, as was already mentioned in \cbfref{ch:RelatedWork} and is discussed in many papers such as~\cite{DRLThatMatters} and~\cite{ReproducibilityRL}. In our simulation framework, with the start of a new episode the market state is always shuffled randomly, to allow RL algorithms to properly explore the environment. This is however creating the problem of creating simulations which are currently impossible to reproduce, which could be solved by \textbf{introducing a seed-based system for shuffling market states and sharing this seed with the user}. When running a different simulation with the same seed, assuming that the marketplace type and environment stay the same, users can recreate the same random market states that are set at the start of an episode, allowing for even better and in-depth comparisons of different vendors, past a single run of the Agent-monitoring tool.

\subsection{Exampleprinter}\label{subsec:FutureExampleprinter}

The Exampleprinter is a great tool for quickly monitoring and evaluating a certain market setup. However, only for one specific combination of marketplace type and market environment, a Duopoly scenario of a Circular Economy with rebuy prices, the animated overview diagram is created. \textbf{Building templates and adding diagram support for more scenarios} should therefore be a priority when enhancing the Exampleprinter. Additionally, the \textbf{market-seed feature} introduced in \bfref{subsec:FutureAgentMonitoring} should also be implemented for the Exampleprinter, to allow users to run a simulation multiple times to monitor possible discrepancies in agent behaviour and find outliers in the data. This could be further enhanced by adding a configuration option that allows for \textbf{more than one episode to be simulated at a time}.

As a combined enhancement for both the Agent-monitoring and the Exampleprinter, the \textbf{Exampleprinter could be integrated into the Agent-monitoring}, while still being its own tool, the same as the Agent-monitoring is integrated into the Live-monitoring.

\subsection{Policyanalyser}\label{subsec:FuturePolicyAnalyser}

The biggest and most important improvement to the Policyanalyser does not concern its concrete features, but the way users interact with it. Currently, all of the other monitoring tools are either integrated into some part of the workflow (e.g. the Live-monitoring), or can easily be started using simple commands, see \cbfref{ch:OurWorkflow}. This is however not the case for the Policyanalyser, which must be started by going into the code itself, which is less than ideal from a user-perspective. So, \textbf{integrating the Policyanalyser into the workflow}, both by \textbf{creating a user-facing interface} for it and by \textbf{adding configuration options to start it after a training session} are features that should be a priority when continuing work on the framework. Users are also able to use the Policyanalyser to analyse a large number and combination of features, so \textbf{curating a list of useful feature combinations to be analysed} would aid many users when using this tool.

\section{Summary}

Using the market simulation framework that was built within the scope of the bachelor's project, users can simulate complex recommerce market situations. Thanks to the modular nature of the framework, different components, such as customer behaviour, can be updated, exchanged or added upon to create a configuration that fits the individual use case. The goal of such simulations is to enable users to implement, test and evaluate various dynamic pricing methods. While classically rule-based pricing methods play a big part in the framework, the majority of implemented and tested pricing methods are those based on RL algorithms, a machine learning technology. The goal of using such algorithms is to automate and optimize the dynamic pricing problem in the recommerce market. By using our framework, users are provided with a large number of tools to monitor, compare and evaluate any combination of pricing methods, enabling them to find the right fit for their needs. The provided tools work on many different levels, from those simulating large amounts of episodes, allowing for an analysis of potential macro-economic implications following specific approaches, to those that work on th smallest possible scale, testing an agent's pricing policy against every possible combination of market states and competitor actions. This allows for a thorough investigation of different strengths and weaknesses of the monitored pricing agents, a necessary prerequisite before being able to employ them in the real market and giving them power over actual pricing decisions.
