\begin{jointwork}
	In this section we want to take a look at what defines an objectively "good" agent, focusing on the dynamic pricing aspect and how our recommerce marketplaces
	were built to simulate real markets as realistically as possible. This section will be split into two parts - first, we will take a look at Reinforcement Learning Agents,
	to then try and transfer as much knowledge as possible to the rulebased competitors we specifically built for the framework.
\end{jointwork}

\section{Reinforcement Learning}

% Before choosing an algorithm to work with, one must be clear about the task the agent will be expected to solve. An algorithm needs a \emph{model of optimality}, which defines
% the way in which the agent will try to optimize its behaviour (i.e. the actions it takes). You can generally differentiate between \emph{finite-horizon} problems and
% \emph{infinite-horizon} problems. In the former, an agent is supposed to optimize rewards for the next \emph{t} steps, while in the latter, rewards should be optimized in the
% long run, with rewards that are further in the future being valued less using a discount factor. 

% In the case of our marketplace simulation framework, we our model of optimality will need to be on the \emph{infinite-horizon}, as the recommerce marketplaces we want to simulate 
% are not time-sensitive but are expected to run indefinitely. 

\section{Overview of market components}
\subsection{Focus on how agents make profit etc.}
\section{How realistic the market is}
\subsection{Restrictions for evaluation arising from this}